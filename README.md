# ğŸ§ª Lab 11 â€” AI Bias & Transparency  
**Course:** AI Ethics / COM  
**Student:** Rasel Ahmmed  
**Topic:** Resume Screening & Explainability in AI Systems  

---

## ğŸ“Œ Exercise 1 â€” Resume Screening AI Bias Analysis

### ğŸ” Dataset Overview
TechCorp uses an AI model to screen software engineering resumes.  
- **Score â‰¥ 70 â‡’ Interview**
- **Human Experts** later reviewed actual qualification.

| Group | Candidates | Actually Qualified |
|-------|------------|-------------------|
| Male  | 50 | 38 |
| Female | 50 | 35 |

---

### ğŸ”¢ Step 1: Interview Rates

#### âœ” **Males Scoring â‰¥ 70**
- 41 out of 50  
- **Interview Rate: 82%**

#### âœ” **Females Scoring â‰¥ 70**
- 34 out of 50  
- **Interview Rate: 68%**

---

### ğŸ§  Step 2: AI Accuracy & False Negatives

#### âœ” **AI Accuracy (Qualified AND Scored â‰¥70)**

| Group | Qualified | Correctly Selected | Accuracy |
|-------|----------|--------------------|----------|
| Male | 38 | 34 | **89.5%** |
| Female | 35 | 27 | **77.1%** |

#### â— False Negatives (Qualified but Scored <70)

| Group | False Negatives |
|-------|-----------------|
| Male | **4** |
| Female | **8** |

ğŸ” **The AI rejects twice as many qualified women.**

---

### ğŸŒ Step 3: Real-World Impact
If TechCorp hires **20 people** based on AI recommendations:

| Group | Interview Share | Expected Hires |
|-------|-----------------|----------------|
| Male | 82% | **â‰ˆ 16** |
| Female | 68% | **â‰ˆ 14 â†’ but limited slots â‡’ â‰ˆ 9** |

âš ï¸ **Female candidates lose opportunities despite similar qualification levels.**

---

### ğŸ§  Step 4: Reflection & Ethical Concerns

#### 6ï¸âƒ£ **Evidence of Bias**
- Higher interview rate for men (82% vs 68%).
- Lower accuracy for qualified women.
- Double rejection of qualified women.

#### 7ï¸âƒ£ **Why This Bias Happens**
- AI may learn from biased historical hiring data.
- Resume wording differences between genders.
- Unbalanced training datasets.

#### 8ï¸âƒ£ **Fixing the System**
- Use **gender-balanced training data**
- **Remove gender indicators** (names, pronouns)
- Perform **fairness audits**
- Use **equal opportunity metrics**
- Continuous improvement & bias monitoring

---

---

## ğŸ­ Exercise 2 â€” AI Decision Transparency Role-Play

### ğŸ” Round 1: Black-Box Decision
- AI denied scholarship without explanation.
- **Emotions:** Confused, powerless, unfair.
- **Problem:** No improvement guidance.

### ğŸ” Round 2: Transparent AI
- Provided weighted scoring & improvement steps.
- **Emotions:** Understood, respected, hopeful.
- **Improvement actions:** Submit SAT scores, add leadership roles.

### ğŸ©º Round 3: Medical AI Scenario
- Explained health risks & next steps.
- **Trust was higher** because reasoning was provided.
- **Transparency increased safety & trust.**

---

### ğŸ§© Final Reflection Summary

| Ethical Impact | Transparent AI | Black-Box AI |
|----------------|----------------|--------------|
| Understanding | Clear reasoning | Confusing |
| Trust | High | Low |
| Actionability | Can improve future | No direction |
| Fairness | Feels fair | Feels biased |

### âš™ï¸ Why Programmers Must Build Explainable AI
- Prevent discrimination & harm.
- Improve user trust and fairness.
- Legally & ethically required in sensitive fields.

### âš ï¸ Challenges
- Hard to explain complex models.
- Risk of exposing proprietary algorithms.
- Must balance clarity & privacy.

---

## ğŸ“Œ Conclusion
âœ” AI systems must be **fair AND explainable**  
âœ” Hidden decision logic increases inequality  
âœ” Transparency empowers users and ensures ethical AI  

---

### ğŸ“ Optional (Ask if needed)
- ğŸ“„ Downloadable PDF version  
- ğŸ—ƒ GitHub folder structure template  
- ğŸ“š References section

> *Prepared by **Rasel Ahmmed**, Lab 11 â€” AI Bias & Transparency.*

